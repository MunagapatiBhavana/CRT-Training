# ğŸ“˜ Day 1: Time Complexity

Welcome to **Day 1** of my DSA Learning Journey!  
Todayâ€™s focus: **Time Complexity** â€“ a fundamental concept to evaluate how efficiently an algorithm performs as input size grows.

---

## ğŸ§  What is Time Complexity?

Amount of time taken for execution of program in a processor.
Time Complexity refers to how the time taken by an algorithm scales with input size `n`.  
It is expressed using **Big O Notation** such as:

- `O(1)` â€“ Constant Time  
- `O(n)` â€“ Linear Time  
- `O(nÂ²)` â€“ Quadratic Time  
- ...and more

### âœ¨ Why It's Important

- ğŸ” **Compare** the efficiency of algorithms  
- âš™ï¸ **Optimize** code performance  
- ğŸ“ˆ **Predict** scalability as data grows  

---

## ğŸ“Š Common Time Complexities

| Big O        | Name         | Description                             | Example                        |
|--------------|--------------|-----------------------------------------|--------------------------------|
| `O(1)`       | Constant      | Executes in the same time always        | Access `arr[0]`                |
| `O(log n)`   | Logarithmic   | Cuts input in half each step            | Binary Search                  |
| `O(n)`       | Linear        | Grows proportionally with input size    | Loop through an array          |
| `O(n log n)` | Linearithmic  | Slightly worse than linear              | Merge Sort, Quick Sort         |
| `O(nÂ²)`      | Quadratic     | Nested loops                            | Bubble Sort                    |
| `O(2â¿)`      | Exponential   | Doubles with each additional input      | Recursive Fibonacci            |
| `O(n!)`      | Factorial     | All permutations                        | Traveling Salesman Problem     |

---

## ğŸ›ï¸ Story: Rahul at the Shopping Mall

Imagine Rahul is shopping in a massive mall to find a T-shirt. His actions reflect different time complexities:

- ğŸŸ¢ **O(1)** â€“ Walks into the first store and buys the first T-shirt.  
- ğŸ”µ **O(n)** â€“ Visits every store one by one before picking one.  
- ğŸŸ¡ **O(log n)** â€“ Uses a sorted mall directory to skip half the options each time.  
- ğŸ”´ **O(nÂ²)** â€“ Compares every T-shirt in every store with every other to find the â€œbest.â€ Overkill!

---

## ğŸ’» Code Examples in C

### ğŸ”¹ O(1) â€“ Constant Time
```c
#include <stdio.h>
int getFirst(int arr[]) {
    return arr[0];
}
int main() {
    int arr[] = {10, 20, 30, 40};
    printf("First element: %d\n", getFirst(arr));
    return 0;
}

ğŸ”¹ O(n) â€“ Linear Time

#include <stdio.h>
void printAll(int arr[], int size) {
    for(int i = 0; i < size; i++) {
        printf("%d\n", arr[i]);
    }
}
int main() {
    int arr[] = {10, 20, 30, 40, 50};
    int size = sizeof(arr) / sizeof(arr[0]);
    printAll(arr, size);
    return 0;
}

ğŸ”¹ O(log n) â€“ Logarithmic Time (Binary Search)

#include <stdio.h>
int binarySearch(int arr[], int size, int key) {
    int low = 0, high = size - 1;
    while (low <= high) {
        int mid = (low + high) / 2;
        if (arr[mid] == key)
            return mid;
        else if (arr[mid] < key)
            low = mid + 1;
        else
            high = mid - 1;
    }
    return -1;
}
int main() {
    int arr[] = {2, 4, 6, 8, 10, 12, 14};
    int size = sizeof(arr) / sizeof(arr[0]);
    int key = 10;
    int result = binarySearch(arr, size, key);
    if (result != -1)
        printf("Element found at index %d\n", result);
    else
        printf("Element not found\n");
    return 0;
}

ğŸ”¹ O(nÂ²) â€“ Quadratic Time

#include <stdio.h>
void allPairs(int arr[], int size) {
    for(int i = 0; i < size; i++) {
        for(int j = 0; j < size; j++) {
            printf("(%d, %d)\n", arr[i], arr[j]);
        }
    }
}
int main() {
    int arr[] = {1, 2, 3};
    int size = sizeof(arr) / sizeof(arr[0]);
    allPairs(arr, size);
    return 0;
}

ğŸ§© Tips to Improve Time Complexity
âœ… Use hash maps for fast lookup instead of brute-force

ğŸ” Eliminate unnecessary nested loops

ğŸ” Prefer binary search on sorted data

âš™ï¸ Choose efficient algorithms (e.g., Merge Sort > Bubble Sort)

ğŸ§  Letâ€™s Simplify It: Time vs Space
ğŸ’¡ Definitions:
Time Complexity â†’ How long code takes to run

Space Complexity â†’ How much memory (RAM) it uses

ğŸšŒ Story: Waiting for a Bus
Imagine you're at a bus stop trying to catch a specific bus. Your behavior shows different complexities:

ğŸ”´ O(nÂ²) â€“ Confused Passenger:
Checks every bus, asks every person. Overthinking and time-consuming.
â±ï¸ Takes a lot of time, ğŸ§  uses too much energy

ğŸŸ¢ O(n) â€“ Careful Observer:
Checks each bus as it comes. Linear checking â€“ practical and simple.

ğŸŸ¢ O(log n) â€“ Smart Commuter:
Uses a bus-tracking app. Only waits when necessary and skips irrelevant buses. Very efficient.
| Scenario                   | Time  | Space | Technique Used    |
| -------------------------- | ----- | ----- | ----------------- |
| Brute-force search         | O(nÂ²) | O(1)  | Nested loops      |
| Hash map for lookups       | O(n)  | O(n)  | Dictionary / Set  |
| Dynamic Programming (Memo) | O(n)  | O(n)  | Memoization table |

ğŸ§  Trade-off: Faster algorithms may use more memory (e.g., caching, DP)

âœ… Final Thoughts
Focus on algorithms with better time complexity

Good time complexity doesn't always mean low memory

Balance time vs space based on problem constraints

Think like Rahul, not the confused bus passenger ğŸ˜‰

